{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESEARCH QUESTION 2 - OUTPUT DIVERSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import csv\n",
    "from collections import Counter\n",
    "from config import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>scopes</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Nov 22 10:54:27 +0000 2020</td>\n",
       "      <td>1330464657086275585</td>\n",
       "      <td>1330464657086275585</td>\n",
       "      <td>Respect @NIkosdN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042467744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Nov 22 10:54:27 +0000 2020</td>\n",
       "      <td>1330464657069531137</td>\n",
       "      <td>1330464657069531137</td>\n",
       "      <td>@TheJasonPugh Putting out the message that ðŸ‡¨ðŸ‡¦ ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.330229e+18</td>\n",
       "      <td>1.330229e+18</td>\n",
       "      <td>4.571369e+08</td>\n",
       "      <td>4.571369e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042467740</td>\n",
       "      <td>[14, 140]</td>\n",
       "      <td>{'full_text': \"@TheJasonPugh Putting out the m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Nov 22 10:54:28 +0000 2020</td>\n",
       "      <td>1330464658650750978</td>\n",
       "      <td>1330464658650750978</td>\n",
       "      <td>@EleriTudor Boris Johnson gets to dictate how ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.330464e+18</td>\n",
       "      <td>1.330464e+18</td>\n",
       "      <td>1.618683e+09</td>\n",
       "      <td>1.618683e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042468117</td>\n",
       "      <td>[12, 140]</td>\n",
       "      <td>{'full_text': \"@EleriTudor Boris Johnson gets ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Nov 22 10:54:28 +0000 2020</td>\n",
       "      <td>1330464658235518977</td>\n",
       "      <td>1330464658235518977</td>\n",
       "      <td>#G20 #COVID19 is hitting every country in the ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042468018</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'full_text': '#G20 #COVID19 is hitting every ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Nov 22 10:54:28 +0000 2020</td>\n",
       "      <td>1330464658940112896</td>\n",
       "      <td>1330464658940112896</td>\n",
       "      <td>500,000 Nigerians to benefit from the Payroll ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042468186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'full_text': '500,000 Nigerians to benefit fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Sun Nov 22 10:54:27 +0000 2020  1330464657086275585  1330464657086275585   \n",
       "1  Sun Nov 22 10:54:27 +0000 2020  1330464657069531137  1330464657069531137   \n",
       "2  Sun Nov 22 10:54:28 +0000 2020  1330464658650750978  1330464658650750978   \n",
       "3  Sun Nov 22 10:54:28 +0000 2020  1330464658235518977  1330464658235518977   \n",
       "4  Sun Nov 22 10:54:28 +0000 2020  1330464658940112896  1330464658940112896   \n",
       "\n",
       "                                                text  \\\n",
       "0                                   Respect @NIkosdN   \n",
       "1  @TheJasonPugh Putting out the message that ðŸ‡¨ðŸ‡¦ ...   \n",
       "2  @EleriTudor Boris Johnson gets to dictate how ...   \n",
       "3  #G20 #COVID19 is hitting every country in the ...   \n",
       "4  500,000 Nigerians to benefit from the Payroll ...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...       True   \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                    NaN                        NaN                  NaN   \n",
       "1           1.330229e+18               1.330229e+18         4.571369e+08   \n",
       "2           1.330464e+18               1.330464e+18         1.618683e+09   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ... filter_level lang   timestamp_ms  \\\n",
       "0                      NaN  ...          low   en  1606042467744   \n",
       "1             4.571369e+08  ...          low   en  1606042467740   \n",
       "2             1.618683e+09  ...          low   en  1606042468117   \n",
       "3                      NaN  ...          low   en  1606042468018   \n",
       "4                      NaN  ...          low   en  1606042468186   \n",
       "\n",
       "  display_text_range                                     extended_tweet  \\\n",
       "0                NaN                                                NaN   \n",
       "1          [14, 140]  {'full_text': \"@TheJasonPugh Putting out the m...   \n",
       "2          [12, 140]  {'full_text': \"@EleriTudor Boris Johnson gets ...   \n",
       "3           [0, 140]  {'full_text': '#G20 #COVID19 is hitting every ...   \n",
       "4                NaN  {'full_text': '500,000 Nigerians to benefit fr...   \n",
       "\n",
       "   extended_entities  possibly_sensitive  withheld_in_countries  scopes  \\\n",
       "0                NaN                 NaN                    NaN     NaN   \n",
       "1                NaN                 NaN                    NaN     NaN   \n",
       "2                NaN                 NaN                    NaN     NaN   \n",
       "3                NaN               False                    NaN     NaN   \n",
       "4                NaN               False                    NaN     NaN   \n",
       "\n",
       "  cluster  \n",
       "0     1.0  \n",
       "1     0.0  \n",
       "2     1.0  \n",
       "3     2.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tweets with cluster information already assigned\n",
    "\n",
    "tweets = pd.read_csv(\"tweets_cluster.csv\")\n",
    "tweets.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PREPROCESS TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\99per\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from array import array\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTerms(text):\n",
    "    \"\"\"\n",
    "    Preprocess the tweet text removing stop words, stemming, transforming to lowercase and return the tokens of \n",
    "    the text.\n",
    "    \n",
    "    Argument:\n",
    "    text -- string (tweet) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    text - a list of tokens (words) corresponding to the input tweet after the preprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Remove Emojis\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    ## Remove \"RT\"\n",
    "    text = text.replace(\"RT \", \"\")\n",
    "     \n",
    "    ## Remove URLs, webpages\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', text)\n",
    "    \n",
    "    ## Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    ## Transform in lowercase\n",
    "    text =  text.lower()\n",
    "\n",
    "    ## Tokenize the text to get a list of terms\n",
    "    text = text.split() \n",
    "\n",
    "    ## Remove stopwords\n",
    "    stops = set(stopwords.words(\"english\"))    \n",
    "    text = [word for word in text if not word in stops] \n",
    "    \n",
    "    ## Perform stemming\n",
    "    stemming = PorterStemmer()\n",
    "    text = [stemming.stem(word) for word in text] \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RANKING SCORE TF-IDF\n",
    "\n",
    "Search engine based on the tweet text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(ids, tweets, data, numDocuments):\n",
    "    \"\"\"\n",
    "    Implement the inverted index for the tweet text and compute the tf, df and idf scores\n",
    "    \n",
    "    Argument:\n",
    "    ids -- tweet ids of the corresponding tweets\n",
    "    tweets -- collection of tweets\n",
    "    numDocuments -- total number of tweets\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a python dictionary) containing terms as keys and the corresponding \n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    \n",
    "    tf - normalized term frequency for each term in each document\n",
    "    \n",
    "    df - number of documents each term appear in\n",
    "    \n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "        \n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)        # term frequencies of terms in documents \n",
    "    df = defaultdict(int)         #document frequencies of terms in the corpus\n",
    "    idf = defaultdict(float)\n",
    "    tweets_terms = []\n",
    "    \n",
    "    for i in range(0, len(tweets)): \n",
    "        ## ===============================================================        \n",
    "        ## create the index for the current doc and store it in termdictPage\n",
    "        ## termdictPage ==> { â€˜term1â€™: [currentdoc, [list of positions]], ..., â€˜termnâ€™: \n",
    "        ##                    [currentdoc, [list of positions]]}\n",
    "        ## ===============================================================\n",
    "        \n",
    "        tweet = tweets[i]\n",
    "        page_id = ids[i]\n",
    "        \n",
    "        termdictPage = {}\n",
    "        \n",
    "        terms = getTerms(tweet)\n",
    "        data.loc[i, 'terms'] = \" \".join(terms)\n",
    "        \n",
    "        ## Iterate over all terms in the tweet\n",
    "        for position, term in enumerate(terms): \n",
    "            try:\n",
    "                # if the term is already in the index for the current page (termdictPage)\n",
    "                # append the position to the corresponding list\n",
    "                termdictPage[term][1].append(position)  \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                termdictPage[term] = [page_id, array('I', [position])]\n",
    "            \n",
    "        ## Merge the current page index with the main index\n",
    "        for termpage, postingpage in termdictPage.items():\n",
    "            index[termpage].append(postingpage[0])\n",
    "        \n",
    "        # normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        \n",
    "        for term, posting in termdictPage.items(): \n",
    "            # posting is a list containing doc_id and the list of positions for current term in current document: \n",
    "            # posting ==> [currentdoc, [list of positions]] \n",
    "            norm += len(posting[1])**2\n",
    "            \n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        # calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in termdictPage.items():     \n",
    "            \n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(len(posting[1])/norm, 4))  \n",
    "            \n",
    "            # increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] += 1  # increment df for current term\n",
    "            \n",
    "    # Compute idf \n",
    "    for term in df:\n",
    "        idf[term] = np.round(np.log(float(numDocuments/df[term])), 4)\n",
    "            \n",
    "    return index, tf, df, idf, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "numDocuments = len(tweets)\n",
    "tweets['terms'] = ['']*numDocuments\n",
    "index, tf, df, idf, tweets = create_index_tfidf(tweets['id'], tweets['text'], tweets, numDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>scopes</th>\n",
       "      <th>cluster</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Nov 22 10:54:27 +0000 2020</td>\n",
       "      <td>1330464657086275585</td>\n",
       "      <td>1330464657086275585</td>\n",
       "      <td>Respect @NIkosdN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042467744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>respect nikosdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Nov 22 10:54:27 +0000 2020</td>\n",
       "      <td>1330464657069531137</td>\n",
       "      <td>1330464657069531137</td>\n",
       "      <td>@TheJasonPugh Putting out the message that ðŸ‡¨ðŸ‡¦ ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.330229e+18</td>\n",
       "      <td>1.330229e+18</td>\n",
       "      <td>4.571369e+08</td>\n",
       "      <td>4.571369e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042467740</td>\n",
       "      <td>[14, 140]</td>\n",
       "      <td>{'full_text': \"@TheJasonPugh Putting out the m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thejasonpugh put messag need plan lockdown alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Nov 22 10:54:28 +0000 2020</td>\n",
       "      <td>1330464658650750978</td>\n",
       "      <td>1330464658650750978</td>\n",
       "      <td>@EleriTudor Boris Johnson gets to dictate how ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.330464e+18</td>\n",
       "      <td>1.330464e+18</td>\n",
       "      <td>1.618683e+09</td>\n",
       "      <td>1.618683e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042468117</td>\n",
       "      <td>[12, 140]</td>\n",
       "      <td>{'full_text': \"@EleriTudor Boris Johnson gets ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eleritudor bori johnson get dictat mani human ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Nov 22 10:54:28 +0000 2020</td>\n",
       "      <td>1330464658235518977</td>\n",
       "      <td>1330464658235518977</td>\n",
       "      <td>#G20 #COVID19 is hitting every country in the ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042468018</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'full_text': '#G20 #COVID19 is hitting every ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>g20 covid19 hit everi countri world caus live ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Nov 22 10:54:28 +0000 2020</td>\n",
       "      <td>1330464658940112896</td>\n",
       "      <td>1330464658940112896</td>\n",
       "      <td>500,000 Nigerians to benefit from the Payroll ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>1606042468186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'full_text': '500,000 Nigerians to benefit fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500000 nigerian benefit payrol support scheme ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Sun Nov 22 10:54:27 +0000 2020  1330464657086275585  1330464657086275585   \n",
       "1  Sun Nov 22 10:54:27 +0000 2020  1330464657069531137  1330464657069531137   \n",
       "2  Sun Nov 22 10:54:28 +0000 2020  1330464658650750978  1330464658650750978   \n",
       "3  Sun Nov 22 10:54:28 +0000 2020  1330464658235518977  1330464658235518977   \n",
       "4  Sun Nov 22 10:54:28 +0000 2020  1330464658940112896  1330464658940112896   \n",
       "\n",
       "                                                text  \\\n",
       "0                                   Respect @NIkosdN   \n",
       "1  @TheJasonPugh Putting out the message that ðŸ‡¨ðŸ‡¦ ...   \n",
       "2  @EleriTudor Boris Johnson gets to dictate how ...   \n",
       "3  #G20 #COVID19 is hitting every country in the ...   \n",
       "4  500,000 Nigerians to benefit from the Payroll ...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...       True   \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                    NaN                        NaN                  NaN   \n",
       "1           1.330229e+18               1.330229e+18         4.571369e+08   \n",
       "2           1.330464e+18               1.330464e+18         1.618683e+09   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ... lang   timestamp_ms display_text_range  \\\n",
       "0                      NaN  ...   en  1606042467744                NaN   \n",
       "1             4.571369e+08  ...   en  1606042467740          [14, 140]   \n",
       "2             1.618683e+09  ...   en  1606042468117          [12, 140]   \n",
       "3                      NaN  ...   en  1606042468018           [0, 140]   \n",
       "4                      NaN  ...   en  1606042468186                NaN   \n",
       "\n",
       "                                      extended_tweet extended_entities  \\\n",
       "0                                                NaN               NaN   \n",
       "1  {'full_text': \"@TheJasonPugh Putting out the m...               NaN   \n",
       "2  {'full_text': \"@EleriTudor Boris Johnson gets ...               NaN   \n",
       "3  {'full_text': '#G20 #COVID19 is hitting every ...               NaN   \n",
       "4  {'full_text': '500,000 Nigerians to benefit fr...               NaN   \n",
       "\n",
       "   possibly_sensitive  withheld_in_countries  scopes  cluster  \\\n",
       "0                 NaN                    NaN     NaN      1.0   \n",
       "1                 NaN                    NaN     NaN      0.0   \n",
       "2                 NaN                    NaN     NaN      1.0   \n",
       "3               False                    NaN     NaN      2.0   \n",
       "4               False                    NaN     NaN      0.0   \n",
       "\n",
       "                                               terms  \n",
       "0                                    respect nikosdn  \n",
       "1  thejasonpugh put messag need plan lockdown alm...  \n",
       "2  eleritudor bori johnson get dictat mani human ...  \n",
       "3  g20 covid19 hit everi countri world caus live ...  \n",
       "4  500000 nigerian benefit payrol support scheme ...  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANK DOCUMENTS ACCORDING TO TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankDocuments(terms, docs, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "        \n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms \n",
    "    # The remaing elements would became 0 when multiplied to the queryVector\n",
    "    docVectors = defaultdict(lambda: [0]*len(terms)) \n",
    "    queryVector = [0]*len(terms)    \n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = Counter(terms) # get the frequency of each term in the query. \n",
    "    \n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "    \n",
    "    for termIndex, term in enumerate(terms): #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "                    \n",
    "        ##Â Compute tf*idf(normalize tf as done with documents)\n",
    "        queryVector[termIndex] = query_terms_count[term]/query_norm * idf[term]\n",
    "\n",
    "        # Generate docVectors for matching docs\n",
    "        for docIndex, doc in enumerate(index[term]):    \n",
    "            if doc in docs:\n",
    "                docVectors[doc][termIndex] = tf[term][docIndex] * idf[term]\n",
    "\n",
    "    # calculate the score of each doc\n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    docScores = [[np.dot(curDocVec, queryVector), doc] for doc, curDocVec in docVectors.items()]\n",
    "    docScores.sort(reverse = True)\n",
    "    resultDocs = [x[1] for x in docScores]\n",
    "    \n",
    "    #print document titles instead of document id's\n",
    "    #resultDocs = [ titleIndex[x] for x in resultDocs ]\n",
    "    if len(resultDocs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        print(\"Query: \", query)\n",
    "        #query = input()\n",
    "        #docs = search_tf_idf(query, index)    \n",
    "    \n",
    "    return resultDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    '''\n",
    "    Outputs the list of documents that contain all of the query terms. \n",
    "    \n",
    "    Argument:\n",
    "    query -- list of query terms\n",
    "    index -- inverted index data structure\n",
    "    \n",
    "    Returns:\n",
    "    Return the list of top 10 documents\n",
    "    \n",
    "    '''\n",
    "    query = getTerms(query)\n",
    "    docs = set()\n",
    "    \n",
    "    # Return docs that contain all query terms\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in termDocs the ids of the docs that contain \"term\"                        \n",
    "            termDocs = [posting for posting in index[term]]\n",
    "\n",
    "            # No documents had been stored yet\n",
    "            if len(docs) == 0:\n",
    "                docs = docs.union(termDocs)\n",
    "            \n",
    "            # Store only documents that are in both sets, meaning that they contained previous terms and current term\n",
    "            else:\n",
    "                docs = docs.intersection(termDocs)\n",
    "\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rankDocuments(query, docs, index, idf, tf)   \n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RERANKING APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(d1_words, d2_words):\n",
    "    d1_words = set(d1_words.split())\n",
    "    d2_words = set(d2_words.split())\n",
    "    sim = len(d1_words.intersection(d2_words))/len(d1_words.union(d2_words))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "## Compute similarity between tweets\n",
    "M = np.zeros((len(tweets), len(tweets)))\n",
    "print(M.shape)\n",
    "\n",
    "for i in range(0, len(tweets)):\n",
    "\n",
    "    for j in range(i + 1, len(tweets)):\n",
    "        sim = compute_similarity(tweets.loc[i, 'terms'], tweets.loc[j, 'terms'])\n",
    "        M[i][j] = sim\n",
    "        M[j][i] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = M.sum(axis = 0, keepdims = 1); \n",
    "sums[sums == 0] = 1\n",
    "M_norm = M/sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute topic richness**\n",
    "\n",
    "The higher the score a tweet's neighbour obtains, the higher its score. Similar to PageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.99\n",
    "mat = c*M_norm + ((1 - c)/numDocuments)*np.ones((numDocuments, numDocuments))\n",
    "\n",
    "# Topic Richness is eigenvector with highest eigenvalue\n",
    "eigvals, eigvecs = la.eigh(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = eigvals.argsort()[::-1]   \n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['topic_richness'] = eigvecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def add_query_results(tweets, docs, query):\n",
    "    i = 1\n",
    "    \n",
    "    result = pd.DataFrame(columns = ['Query', 'Result', 'Tweet', 'Id', 'User', 'Date', 'Hashtags', 'Cluster', \n",
    "                                     'TopicRichness'])\n",
    "    \n",
    "    for doc_id in docs:\n",
    "        tweet = tweets[tweets['id'] == doc_id]\n",
    "        tid = tweets[tweets['id'] == doc_id].index.item()\n",
    "        user = tweet['user'].item()\n",
    "        user = ast.literal_eval(user)\n",
    "        entities = tweet['entities'].item()\n",
    "        entities = ast.literal_eval(entities)\n",
    "        hashtags = [hashtag['text'] for hashtag in entities['hashtags']]\n",
    "        \n",
    "        result = result.append({'Query': query, 'Result': i, 'Tweet': tweet['text'].item(), 'Id': tid, \n",
    "                                'User': user['screen_name'], 'Date': tweet['created_at'].item(), 'Hashtags': hashtags, \n",
    "                                'Cluster': tweet['cluster'].item(), 'TopicRichness': tweet['topic_richness'].item(),\n",
    "                                'Words': tweet['terms'].item()}, \n",
    "                               ignore_index = True)\n",
    "        i = i + 1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"test\", \"coronavirus\", \"realdonaldtrump\"]\n",
    "results_ranking = pd.DataFrame()\n",
    "top = 100\n",
    "\n",
    "for query in queries:\n",
    "    ranked_docs = search_tf_idf(query, index)\n",
    "    results_ranking = results_ranking.append(add_query_results(tweets, ranked_docs[:top], query), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Result</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Id</th>\n",
       "      <th>User</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>TopicRichness</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>\"As the @WHO's Dr. Tedros said very emphatical...</td>\n",
       "      <td>5710</td>\n",
       "      <td>manigreeva</td>\n",
       "      <td>Sun Nov 22 11:12:43 +0000 2020</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>who dr tedro said emphat outset test test test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>Loeffler tests positive for Covid but undergoi...</td>\n",
       "      <td>9774</td>\n",
       "      <td>bote930</td>\n",
       "      <td>Sun Nov 22 11:26:46 +0000 2020</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>loeffler test posit covid undergo test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>@mel_faith1 The thing is is there is NO test f...</td>\n",
       "      <td>6685</td>\n",
       "      <td>susanlee52</td>\n",
       "      <td>Sun Nov 22 11:16:15 +0000 2020</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>mel_faith1 thing test covid test viru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "      <td>Testing. Testing. Covid/TheDanes: 'They kept i...</td>\n",
       "      <td>3034</td>\n",
       "      <td>Fuerza_Mundial</td>\n",
       "      <td>Sun Nov 22 11:04:34 +0000 2020</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>test test covidthedan kept month18 mask wearer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>Loeffler tests positive for Covid but undergoi...</td>\n",
       "      <td>472</td>\n",
       "      <td>DeeFonta</td>\n",
       "      <td>Sun Nov 22 10:56:01 +0000 2020</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>loeffler test posit covid undergo test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Query Result                                              Tweet    Id  \\\n",
       "0  test      1  \"As the @WHO's Dr. Tedros said very emphatical...  5710   \n",
       "1  test      2  Loeffler tests positive for Covid but undergoi...  9774   \n",
       "2  test      3  @mel_faith1 The thing is is there is NO test f...  6685   \n",
       "3  test      4  Testing. Testing. Covid/TheDanes: 'They kept i...  3034   \n",
       "4  test      5  Loeffler tests positive for Covid but undergoi...   472   \n",
       "\n",
       "             User                            Date Hashtags  Cluster  \\\n",
       "0      manigreeva  Sun Nov 22 11:12:43 +0000 2020       []      0.0   \n",
       "1         bote930  Sun Nov 22 11:26:46 +0000 2020       []      0.0   \n",
       "2      susanlee52  Sun Nov 22 11:16:15 +0000 2020       []      0.0   \n",
       "3  Fuerza_Mundial  Sun Nov 22 11:04:34 +0000 2020       []      0.0   \n",
       "4        DeeFonta  Sun Nov 22 10:56:01 +0000 2020       []      0.0   \n",
       "\n",
       "   TopicRichness                                              Words  \n",
       "0       0.000095  who dr tedro said emphat outset test test test...  \n",
       "1       0.001846             loeffler test posit covid undergo test  \n",
       "2      -0.000322              mel_faith1 thing test covid test viru  \n",
       "3       0.000736  test test covidthedan kept month18 mask wearer...  \n",
       "4       0.005545             loeffler test posit covid undergo test  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ranking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reranking strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(result, i):\n",
    "    return {'Query': result['Query'], 'RankRes': result['Result'], 'RerankRes': i, 'Tweet': result['Tweet'], \n",
    "            'User': result['User'], 'Date': result['Date'], 'Hashtags': result['Hashtags'], \n",
    "            'Cluster': result['Cluster'], 'TopicRichness': result['TopicRichness'], 'Words': result['Words']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reranking(results_ranking, M, top):\n",
    "\n",
    "    result = pd.DataFrame(columns = ['Query', 'RankRes', 'RerankRes', 'Tweet', 'User', 'Date', 'Hashtags', 'Cluster', \n",
    "                                     'TopicRichness', 'Words'])\n",
    "    \n",
    "    max_ = len(results_ranking) if len(results_ranking) < top else top\n",
    "    for i in range(0, max_):\n",
    "        # Get the result with highest Topic Richness\n",
    "        results_ranking = results_ranking.sort_values(by = [\"TopicRichness\"], ascending = False)\n",
    "        results_ranking = results_ranking.reset_index()\n",
    "        results_ranking.drop(columns = ['index'], inplace = True)\n",
    "        \n",
    "        #print(results_ranking)\n",
    "        d_id = results_ranking.loc[0, 'Id']\n",
    "        tr = results_ranking.loc[0, 'TopicRichness']\n",
    "        \n",
    "        result = result.append(add_result(results_ranking.iloc[0], i + 1), ignore_index = True)\n",
    "        #result = result.append(results_ranking.iloc[0])\n",
    "        results_ranking.drop(0, inplace = True)\n",
    "        \n",
    "        # Recompute Topic Richness\n",
    "        for j in range(1, len(results_ranking)):\n",
    "            n_id = results_ranking.loc[j, 'Id']\n",
    "            results_ranking.loc[j, 'TopicRichness'] = results_ranking.loc[j, 'TopicRichness'] - M[n_id][d_id]*tr\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reranking = pd.DataFrame()\n",
    "\n",
    "for query in results_ranking['Query'].unique():\n",
    "    results = results_ranking[results_ranking['Query'] == query]\n",
    "\n",
    "    results_reranking = results_reranking.append(reranking(results, M_norm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ranking = results_ranking[results_ranking['Result'].isin(range(1, 21))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diversity score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_words(texts_):\n",
    "    \n",
    "    words_docs = {}\n",
    "    for _, row in texts_.iteritems():\n",
    "        for word in row.split():\n",
    "            \n",
    "            if word not in words_docs.keys():\n",
    "                words_docs[word] = 0\n",
    "            \n",
    "            words_docs[word] += 1\n",
    "            \n",
    "    return words_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = {}\n",
    "\n",
    "for query in results_reranking['Query'].unique():\n",
    "    DS_query = 0\n",
    "    results = results_reranking[results_reranking['Query'] == query]\n",
    "    \n",
    "    df_results = compute_words(results['Words'])\n",
    "    for _, row in results.iterrows():\n",
    "        inter = 0\n",
    "        for word in row['Words'].split():\n",
    "            inter += 1/df_results[word]\n",
    "        if len(row['Words'].split()) != 0:\n",
    "            DS_query += inter/len(row['Words'].split())\n",
    "    DS[query] = DS_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 12.579391605126897,\n",
       " 'coronavirus': 13.735857142857142,\n",
       " 'realdonaldtrump': 15.072341269841267}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RANKING DIFFERENCE AND COVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.13984962406015036\n",
      "coronavirus 0.018045112781954885\n",
      "realdonaldtrump 0.03909774436090225\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "for query in results_ranking['Query'].unique():\n",
    "    results_rank = results_ranking[results_ranking['Query'] == query]['Result']\n",
    "    results_rerank = results_reranking[results_reranking['Query'] == query]['RankRes']\n",
    "    \n",
    "    corr, p = spearmanr(results_rank, results_rerank)\n",
    "    print(query, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "\t Ranking coverage: 1\n",
      "\t Re-ranking coverage: 2\n",
      "\n",
      "coronavirus\n",
      "\t Ranking coverage: 1\n",
      "\t Re-ranking coverage: 2\n",
      "\n",
      "realdonaldtrump\n",
      "\t Ranking coverage: 2\n",
      "\t Re-ranking coverage: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in results_ranking['Query'].unique():\n",
    "    print(query)\n",
    "    print('\\t Ranking coverage: ' + str(results_ranking[results_ranking['Query'] == query]['Cluster'].nunique()))\n",
    "    print('\\t Re-ranking coverage: ' + str(results_reranking[results_reranking['Query'] == query]['Cluster'].nunique()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_info(results, rerank = True):\n",
    "    \n",
    "    for _, row in results.iterrows():\n",
    "        if rerank:\n",
    "            print(str(row['RerankRes']) + '. \\tTweet: ' + row['Tweet'] + '\\t User: ' + row['User'] + \n",
    "                  '\\t Date: ' + row['Date'] + '\\t Hashtags: ' + str(row['Hashtags']) + '\\t Cluster: ' + \n",
    "                  str(row['Cluster']) + '\\t TopicRichness ' + str(row['TopicRichness']))\n",
    "        else:\n",
    "            print(str(row['Result']) + '. \\tTweet: ' + row['Tweet'] + '\\t User: ' + row['User'] + \n",
    "                  '\\t Date: ' + row['Date'] + '\\t Hashtags: ' + str(row['Hashtags']) + '\\t Cluster: ' + \n",
    "                  str(row['Cluster']) + '\\t TopicRichness ' + str(row['TopicRichness']))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \tTweet: \"As the @WHO's Dr. Tedros said very emphatically at the very outset: â€œTest, test, testâ€. As a physician, I wish heâ€™â€¦ https://t.co/n3Dn2NwnlE\t User: manigreeva\t Date: Sun Nov 22 11:12:43 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 9.512778224714583e-05\n",
      "2. \tTweet: Loeffler tests positive for Covid but undergoing further testing\n",
      "https://t.co/5ulPDNmhne\t User: bote930\t Date: Sun Nov 22 11:26:46 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0018463648458519586\n",
      "3. \tTweet: @mel_faith1 The thing is is there is NO test for Covid! The test is for a virus only\t User: susanlee52\t Date: Sun Nov 22 11:16:15 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -0.00032220929354842965\n",
      "4. \tTweet: Testing. Testing. Covid/TheDanes: 'They kept it up for a month.1.8% of mask wearers tested positive &amp; 2.1% of the uâ€¦ https://t.co/Oc5tGJDuuH\t User: Fuerza_Mundial\t Date: Sun Nov 22 11:04:34 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0007356799139667318\n",
      "5. \tTweet: Loeffler tests positive for Covid but undergoing further testing\n",
      "https://t.co/c06EbCUbZA\t User: DeeFonta\t Date: Sun Nov 22 10:56:01 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.005544894615846776\n",
      "6. \tTweet: @GBPublicHealth Is every patient that takes a Covid test taking a flu test too? Did you stop testing for the flu alâ€¦ https://t.co/mTMNKwvEox\t User: theresabeverag1\t Date: Sun Nov 22 11:17:51 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0001079470604193416\n",
      "7. \tTweet: Georgia Sen. Kelly Loeffler tests positive for Covid but is undergoing further testing.\n",
      "https://t.co/rYLPlhyaQw\t User: MrsVSNC09\t Date: Sun Nov 22 11:09:31 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.00021246960902998092\n",
      "8. \tTweet: KARMA.......Georgia Sen. Kelly Loeffler tests positive for Covid but is undergoing further testing - CNNâ€¦ https://t.co/JFRCgDaqko\t User: m0m19001\t Date: Sun Nov 22 11:18:43 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -2.3258388781474113e-05\n",
      "9. \tTweet: @safiume Or better testing: https://t.co/Iaif2cdF7b\t User: nahumshalman\t Date: Sun Nov 22 11:17:39 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 1.5596213889095625e-05\n",
      "10. \tTweet: #YEDNOnCovid19 have you been tested for #coronavirus ?if not ,visit the #coronavirus center to get tested?â€¦ https://t.co/dt3dDD20xd\t User: MutieMumbua\t Date: Sun Nov 22 11:16:00 +0000 2020\t Hashtags: ['YEDNOnCovid19', 'coronavirus', 'coronavirus']\t Cluster: 0.0\t TopicRichness -0.0002665741964422599\n",
      "11. \tTweet: ...and testing negative for ethics.\t User: DanDiego\t Date: Sun Nov 22 11:10:43 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -0.00047904748160322987\n",
      "12. \tTweet: @DailyMirror Mass testing should not stop at 2 test but should be continuously carried out until we know where the virus is and who has it .\t User: STSIMON95984452\t Date: Sun Nov 22 11:09:40 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -0.00026378831698467195\n",
      "13. \tTweet: @JonLoflin that's the problem.  this test cannot tell and as virus is more spread in a population, the % of tests tâ€¦ https://t.co/A0Kd0X4xeF\t User: boriquagato\t Date: Sun Nov 22 11:05:43 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -0.00028522254319739924\n",
      "14. \tTweet: Over 170 million coronavirus tests have already been given in the U.S. and itâ€™s territories. The tests are availablâ€¦ https://t.co/mNXppr2AQp\t User: suebrown1212\t Date: Sun Nov 22 10:58:53 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -0.00046320579387470166\n",
      "15. \tTweet: ð—¡ð—²ð—½ð—®ð—¹ ð—–ð—¢ð—©ð—œð——-ðŸ­ðŸµ ð—¦ð˜ð—®ð˜ð˜‚ð˜€\n",
      "Tests (PCR): 1,660,075\n",
      "Tests (RDT): 312,402\n",
      "Positive: 220,308\n",
      "Recovered: 199,024\n",
      "In Isolationâ€¦ https://t.co/UZeNF075zy\t User: NepalCorona\t Date: Sun Nov 22 11:19:23 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.00018272871298968536\n",
      "16. \tTweet: Kelly Loeffler tests positive for Covid but undergoing further testing - CNNPolitics #Mtnews #Georgia #CDC  https://t.co/BevWrVugTC\t User: stewardmagazine\t Date: Sun Nov 22 11:17:41 +0000 2020\t Hashtags: ['Mtnews', 'Georgia', 'CDC']\t Cluster: 0.0\t TopicRichness -0.0004969932538576234\n",
      "17. \tTweet: â€œTesting doesnâ€™t matterâ€ -my family in reference to COVID testing before any thanksgiving plans...... \n",
      "\n",
      "Word... wheâ€¦ https://t.co/aOnzp7EccS\t User: megadillo\t Date: Sun Nov 22 11:12:42 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 3.294920318003694e-05\n",
      "18. \tTweet: @jksmith34 Test and trace is a joke everywhere and testing someone for a virus that can catch a minute after the teâ€¦ https://t.co/iEpxhLsWzb\t User: SFotonium\t Date: Sun Nov 22 11:10:08 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness -3.818399839290601e-05\n",
      "19. \tTweet: BOMBSHELLLL! DO NOT GET TESTED FOR COVID. PCR TESTS ARE a TOTAL FRAUD. 100% PROOF | jmviverlivre https://t.co/3GLvykjNKr\t User: oscar226622\t Date: Sun Nov 22 11:09:31 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.00026555644196820863\n",
      "20. \tTweet: Most #COVID19 test sites are open everyday, including at the weekend.\n",
      "\n",
      "If you have any symptoms, book a test. \n",
      "\n",
      "Remâ€¦ https://t.co/LBotsgxI1b\t User: HyndburnCouncil\t Date: Sun Nov 22 11:08:13 +0000 2020\t Hashtags: ['COVID19']\t Cluster: 0.0\t TopicRichness -5.467215652865927e-05\n"
     ]
    }
   ],
   "source": [
    "# Ranking Results for test\n",
    "print_results_info(results_ranking[results_ranking['Query'] == \"test\"], rerank = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \tTweet: Loeffler tests positive for Covid but undergoing further testing\n",
      "https://t.co/c06EbCUbZA\t User: DeeFonta\t Date: Sun Nov 22 10:56:01 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.005544894615846776\n",
      "2. \tTweet: Jesus H Christ it's worse than I thought! Never mind a covid test, this guy needs to have an IQ test twice a week.\t User: PrimLikeARose\t Date: Sun Nov 22 10:54:42 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.005485703194656347\n",
      "3. \tTweet: Breaking: Loeffler self-isolating after mixed coronavirus test results https://t.co/x2YfWTfJb5\t User: JClickbaited\t Date: Sun Nov 22 10:57:43 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0023553949569966384\n",
      "4. \tTweet: Loeffler tests positive for Covid but undergoing further testing\n",
      "https://t.co/5ulPDNmhne\t User: bote930\t Date: Sun Nov 22 11:26:46 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0018099505249776567\n",
      "5. \tTweet: COVID testing workers needed for mass departure testing programme.\n",
      "Find out more and apply for the role:â€¦ https://t.co/7kvGczY9c2\t User: UoNCareers\t Date: Sun Nov 22 11:00:27 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.001273754892719232\n",
      "6. \tTweet: COVID-19 symptoms? Get tested.\n",
      "How? Drop in to a drop-in testing clinic. No appointment or referral needed.\n",
      "Where?â€¦ https://t.co/TrabvMZm5w\t User: PEIwellness\t Date: Sun Nov 22 11:00:39 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0008455250753981433\n",
      "7. \tTweet: Frequent, rapid testing can curb Covid-19 transmission within weeks:Â Study https://t.co/w8zFo3N2BI\t User: India_NewsLive\t Date: Sun Nov 22 11:21:27 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0008369674199248415\n",
      "8. \tTweet: Testing. Testing. Covid/TheDanes: 'They kept it up for a month.1.8% of mask wearers tested positive &amp; 2.1% of the uâ€¦ https://t.co/Oc5tGJDuuH\t User: Fuerza_Mundial\t Date: Sun Nov 22 11:04:34 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0007255492716783944\n",
      "9. \tTweet: @GOVUK Why is the government lying about the reliability of PCR testing?\n",
      "https://t.co/8DW9i2Ato2\t User: JoeMcA90\t Date: Sun Nov 22 11:19:29 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.000611492139616731\n",
      "10. \tTweet: UP to test people coming in from Delhi for COVID-19\n",
      "https://t.co/3Fkp6WwRgS\t User: digiworldblog\t Date: Sun Nov 22 11:20:37 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0005701402243481313\n",
      "11. \tTweet: The long lines outside the test centers this weekend indicate that many people are ignoring this -- a negative testâ€¦ https://t.co/0EVQRbDFJ6\t User: jandev\t Date: Sun Nov 22 11:23:48 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0005450652876380173\n",
      "12. \tTweet: Frequent, rapid testing could cripple COVID-19 within weeks, study shows: Research shows test turnaround-time, freqâ€¦ https://t.co/nMUcNz8S4D\t User: tomhathaway01\t Date: Sun Nov 22 11:18:36 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0005231336625585913\n",
      "13. \tTweet: I love that song by COVID House \"4 Tests in just 1 Day\"\t User: MadamCurious\t Date: Sun Nov 22 11:16:53 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.00048286459496159036\n",
      "14. \tTweet: The COVID-19 RT-PCR Test: How to Mislead All Humanity. Using a â€œTestâ€ To Lock Down Society https://t.co/mv7b3lLXYg via @grtvnews\t User: nk2008\t Date: Sun Nov 22 11:07:07 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.00047462177249001927\n",
      "15. \tTweet: @davidgmac9 @fionamflanagan1 Tested? It takes at least 15 years of testing for a vaccine to be presumed safe. You câ€¦ https://t.co/Jo19kgvBxn\t User: NolullabyJohn\t Date: Sun Nov 22 11:01:18 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0004692717228146852\n",
      "16. \tTweet: A total of 17 teachers &amp; teaching staff test #COVID19 positive out of 5,671 samples tested in the rural area of Punâ€¦ https://t.co/LDBuZpqcjM\t User: ConnectGujarat\t Date: Sun Nov 22 11:23:17 +0000 2020\t Hashtags: ['COVID19']\t Cluster: 0.0\t TopicRichness 0.00036611396600012695\n",
      "17. \tTweet: @ZDFheute COVID TESTING FRAUD UNCOVERED - The Highwire\n",
      "https://t.co/9BCJxtgYSC\t User: AndreaKhne1\t Date: Sun Nov 22 11:26:43 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.000362142840752674\n",
      "18. \tTweet: So why would they pay billions to test so many people for a common cold coronavirus ? Are the tests even real ? Orâ€¦ https://t.co/kzuLJmUNzR\t User: YamaNiyamaSatya\t Date: Sun Nov 22 11:20:37 +0000 2020\t Hashtags: []\t Cluster: 2.0\t TopicRichness 0.00033979092324205634\n",
      "19. \tTweet: BOMBSHELLLL! DO NOT GET TESTED FOR COVID. PCR TESTS ARE a TOTAL FRAUD. 100% PROOF | jmviverlivre https://t.co/3GLvykjNKr\t User: oscar226622\t Date: Sun Nov 22 11:09:31 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.0002475296564257298\n",
      "20. \tTweet: All going from Delhi to Noida to be tested everyday?!\t User: sangeetasanghvi\t Date: Sun Nov 22 11:24:26 +0000 2020\t Hashtags: []\t Cluster: 0.0\t TopicRichness 0.00024470897531631084\n"
     ]
    }
   ],
   "source": [
    "# Reranking Results for test\n",
    "print_results_info(results_reranking[results_reranking['Query'] == \"test\"], rerank = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
