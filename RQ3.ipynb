{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PROJECT - RESEARCH QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from collections import Counter\n",
    "from config import *\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 7min 36s, total: 9min 17s\n",
      "Wall time: 31min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"data/tweets.json\", \"rb\") as f:\n",
    "    data = f.readlines()\n",
    "    data = [json.loads(str_) for str_ in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 2min 11s, total: 2min 30s\n",
      "Wall time: 13min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tweets = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_100 = df_tweets[:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CREATE THE RETWEET GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweet graph \n",
    "df_retweets = df_tweets_100[~df_tweets_100['retweeted_status'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pd.DataFrame(columns = [\"source\", \"destination\"])\n",
    "\n",
    "# add source-nodes\n",
    "df_graph[\"source\"] = df_retweets['user'].apply(lambda x: x['screen_name'])\n",
    "\n",
    "# add destination-nodes\n",
    "df_graph[\"destination\"] =  df_retweets['retweeted_status'].apply(lambda x: x['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [tuple(x) for x in df_graph.values]\n",
    "graph = Graph.TupleList(tuples, directed = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64203\n"
     ]
    }
   ],
   "source": [
    "print(len(graph.es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TESTING ALGORITHMS USING THE FIRST OPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12840\n"
     ]
    }
   ],
   "source": [
    "# fraction of edges to select as test-set\n",
    "p = 0.2\n",
    "\n",
    "# graphsize\n",
    "N = len(graph.es)\n",
    "\n",
    "# idxs of all the edges\n",
    "all_idxs = range(N)\n",
    "\n",
    "# sample idxs of edges through the function \"choice\"\n",
    "test_idxs = np.random.choice(a = all_idxs, size = int(p*N), replace = False)\n",
    "\n",
    "print(len(test_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the test edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51363\n"
     ]
    }
   ],
   "source": [
    "graph_del = Graph.TupleList(tuples, directed = False)\n",
    "graph_del.delete_edges(test_idxs)\n",
    "print(len(graph_del.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set()\n",
    "trainset = set()\n",
    "\n",
    "for idx, one_edge in enumerate(graph.es):\n",
    "\n",
    "    # take n1 and n2 idx from one_edge, that is an igraph edge *object*\n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "\n",
    "    if idx in test_idxs:\n",
    "        ground_truth.add((n1, n2, 1))\n",
    "        \n",
    "    else:\n",
    "        trainset.add((n1, n2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15455"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nodes = set()\n",
    "for n1, n2, _ in ground_truth:\n",
    "    unique_nodes.add(n1)\n",
    "    unique_nodes.add(n2)\n",
    "\n",
    "len(unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nodes_at_distance_2(graph, nodes):\n",
    "    \"\"\"\n",
    "    starting from a graph this function returns all the nodes at distance 2\n",
    "    \"\"\"\n",
    "    \n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    for n1 in nodes:\n",
    "        \n",
    "        # all the nodes at distance 1\n",
    "        nodes_at_most_distant_1 = set(graph.neighborhood(vertices = n1, order = 1))\n",
    "\n",
    "        # all the nodes at distance 1 and distance 2\n",
    "\n",
    "        nodes_at_most_distant_2 = set(graph.neighborhood(vertices = n1, order = 2))\n",
    "        \n",
    "        # only the nodes at distance 2\n",
    "        only_nodes_at_distance_2 = nodes_at_most_distant_2 - nodes_at_most_distant_1\n",
    "        \n",
    "        \n",
    "        # check if empty set\n",
    "        if len(only_nodes_at_distance_2) > 0:\n",
    "\n",
    "            for n2 in only_nodes_at_distance_2:\n",
    "                \n",
    "                all_potential_recommendations.add((n1, n2))\n",
    "            \n",
    "    return all_potential_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.7 s, sys: 2.97 s, total: 5.67 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_potential_recommendations = find_nodes_at_distance_2(graph_del, unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068330"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_potential_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in all_potential_recommendations:\n",
    "    \n",
    "    # add to ground truth also the potential nodes\n",
    "    n1 = rec[0]\n",
    "    n2 = rec[1]\n",
    "    \n",
    "    ground_truth.add((n1, n2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081170\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we get the adjacency matrix of tweets\n",
    "M = graph_del.get_adjacency_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c91ce0d50145dab29103e39bc776db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# here we run the model ALS\n",
    "model = implicit.als.AlternatingLeastSquares(factors = 10, calculate_training_loss = True, iterations = 5)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ALS(testset, model):\n",
    "    \"\"\"\n",
    "    predict for a list of observations the score for adding/removing a link\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "\n",
    "    # scroll the obs\n",
    "    for n1, n2, w in testset:\n",
    "        \n",
    "        # take here the low-dimensional vectors returned by the matrix factorization\n",
    "        \n",
    "        array_n1 = model.user_factors[n1,:]\n",
    "        array_n2 = model.item_factors[n2,:]\n",
    "\n",
    "        # multiplying these vectors we generate an approximation for the edge score\n",
    "        one_p = np.dot(array_n1, array_n2)\n",
    "\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_test = pd.DataFrame(list(ground_truth), columns = [\"n1\", \"n2\", \"edge\"])\n",
    "all_predictions = predict_ALS(df_test.values, model)\n",
    "\n",
    "# add predictions to df\n",
    "df_test[\"rating\"] = all_predictions\n",
    "\n",
    "# convert predictions to binary values: 0 don't add the edge, 1 add it.\n",
    "df_test[\"rating\"] = df_test[\"rating\"].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9881054783244079"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of observations matched by the prediction\n",
    "right_predictions = len(df_test[df_test['rating'] == df_test['edge']])\n",
    "\n",
    "# accuracy\n",
    "right_predictions/len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAMIC ADAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ADA(u, v, graph):\n",
    "    \"\"\"\n",
    "    compute adamic-adar from scratch\n",
    "    \"\"\"\n",
    "    \n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = graph.neighbors(u)\n",
    "\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = graph.neighbors(v)\n",
    "\n",
    "    # set Z of neighbors of both\n",
    "    bridges = set(outlinks_from_u).intersection(inlinks_to_v)\n",
    "\n",
    "    # degree of nodes in set Z\n",
    "    deg_ = [graph.degree(n) for n in bridges]\n",
    "    \n",
    "    # computing the reciprocal in log-scale\n",
    "    out = [1./np.log2(dd+1) for dd in deg_]\n",
    "\n",
    "    return sum(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JACCARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Jaccard(u,v, graph):\n",
    "    \"\"\"\n",
    "    compute jaccard similarity\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = graph.neighbors(u)\n",
    "\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = graph.neighbors(v)\n",
    "\n",
    "    # intesection of the two sets\n",
    "    num = set(outlinks_from_u).intersection(inlinks_to_v)\n",
    "    \n",
    "    # union of the two sets\n",
    "    den = set(outlinks_from_u).union(inlinks_to_v)\n",
    "    \n",
    "    # final division\n",
    "    if len(den) == 0:\n",
    "        out = 0\n",
    "    else:\n",
    "        out = len(num)/len(den)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAGERANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique nodes\n",
    "unique_nodes = set()\n",
    "for n1, n2, _ in ground_truth:\n",
    "    unique_nodes.add(n1)\n",
    "    unique_nodes.add(n2)\n",
    "\n",
    "# Subset of 100 nodes\n",
    "test_nodes = list(unique_nodes)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges in the test set involving the test_nodes\n",
    "test_ground_truth = set()\n",
    "\n",
    "for n1, n2, val in ground_truth:\n",
    "    if n1 in test_nodes or n2 in test_nodes:\n",
    "        test_ground_truth.add((n1, n2, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10841\n"
     ]
    }
   ],
   "source": [
    "print(len(test_nodes))\n",
    "print(len(test_ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.8 s, sys: 1.58 s, total: 52.3 s\n",
      "Wall time: 59.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topk = 10\n",
    "\n",
    "# Dataframe to store the top10 for each node\n",
    "ADA_results = pd.DataFrame()\n",
    "Jaccard_results = pd.DataFrame()\n",
    "PageRank_results = pd.DataFrame()\n",
    "\n",
    "# Iterate over the nodes in the test set\n",
    "for node in test_nodes:\n",
    "    \n",
    "    # Create temporal datasets\n",
    "    ADA_tmp = pd.DataFrame()\n",
    "    Jaccard_tmp = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over the test_ground_truth set\n",
    "    for n1, n2, val in test_ground_truth:\n",
    "        \n",
    "        # Comptue the predicitons for the algorithms: ADA, Jaccard\n",
    "        if node == n1:\n",
    "            ADA_tmp = ADA_tmp.append({'source': node, 'destination': n2, 'true': val,\n",
    "                                      'ADA_pred': compute_ADA(node, n2, graph_del)}, ignore_index = True)\n",
    "            Jaccard_tmp = Jaccard_tmp.append({'source': node, 'destination': n2, 'true': val, \n",
    "                                              'Jaccard_pred': compute_Jaccard(node, n2, graph_del)}, \n",
    "                                             ignore_index = True)\n",
    "            \n",
    "        elif node == n2:\n",
    "            ADA_tmp = ADA_tmp.append({'source': node, 'destination': n1, 'true': val, \n",
    "                                      'ADA_pred': compute_ADA(n1, node, graph_del)}, ignore_index = True)\n",
    "            Jaccard_tmp = Jaccard_tmp.append({'source': node, 'destination': n1, 'true': val, \n",
    "                                              'Jaccard_pred': compute_Jaccard(n1, node, graph_del)}, \n",
    "                                             ignore_index = True)\n",
    "    \n",
    "    # Store the top10 \n",
    "    ADA_tmp.sort_values(by = ['ADA_pred'], inplace = True, ascending = False)\n",
    "    ADA_results = ADA_results.append(ADA_tmp[:topk])\n",
    "    \n",
    "    Jaccard_tmp.sort_values(by = ['Jaccard_pred'], inplace = True, ascending = False)\n",
    "    Jaccard_results = Jaccard_results.append(Jaccard_tmp[:topk])\n",
    "    \n",
    "    # PageRank algorithm\n",
    "    pr = enumerate(graph_del.personalized_pagerank(reset_vertices = node))\n",
    "    out = sorted(pr, key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    i = 0\n",
    "    for node2, pagerank in out:\n",
    "        if i < topk and node != node2:\n",
    "            for n1, n2, val in test_ground_truth:\n",
    "                if node2 == n1 or node2 == n2:\n",
    "                    i = i + 1\n",
    "                    PageRank_results = PageRank_results.append({'source': node, 'destination': node2, 'true': val, \n",
    "                                                                'PageRank_pred': pagerank}, ignore_index = True)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ADA_pred  destination  source  true\n",
      "0   0.141738       2084.0     2.0   0.0\n",
      "1   0.141738      11719.0     2.0   0.0\n",
      "30  0.141738       7048.0     2.0   0.0\n",
      "29  0.141738       6370.0     2.0   0.0\n",
      "28  0.141738      39355.0     2.0   0.0\n"
     ]
    }
   ],
   "source": [
    "print(ADA_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Jaccard_pred  destination  source  true\n",
      "19           1.0      55140.0     2.0   0.0\n",
      "18           1.0      47586.0     2.0   0.0\n",
      "24           1.0      35741.0     2.0   0.0\n",
      "30           1.0       7048.0     2.0   0.0\n",
      "6            1.0        976.0     2.0   0.0\n"
     ]
    }
   ],
   "source": [
    "print(Jaccard_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PageRank_pred  destination  source  true\n",
      "0       0.239992          3.0     2.0   0.0\n",
      "1       0.016956         31.0     2.0   1.0\n",
      "2       0.014829        153.0     2.0   0.0\n",
      "3       0.010863         27.0     2.0   0.0\n",
      "4       0.006428        795.0     2.0   0.0\n"
     ]
    }
   ],
   "source": [
    "print(PageRank_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for nDCG metrics are:\n",
      "\n",
      "ADA score 0.0815\n",
      "Jaccard score 0.0865\n",
      "PageRank score 0.3238\n"
     ]
    }
   ],
   "source": [
    "# NDCG score computation\n",
    "ADA_score_nDCG = dict()\n",
    "Jaccard_score_nDCG = dict()\n",
    "PageRank_score_nDCG = dict()\n",
    "\n",
    "\n",
    "for node in test_nodes:\n",
    "    if len(ADA_results[ADA_results['source'] == node]) > 1:\n",
    "        ADA_score_nDCG[node] = ndcg_score(np.asarray([ADA_results[ADA_results['source'] == node]['true'].values]), \n",
    "                                          np.asarray([ADA_results[ADA_results['source'] == node]['ADA_pred'].values]))\n",
    "    \n",
    "    if len(Jaccard_results[Jaccard_results['source'] == node]) > 1:\n",
    "        Jaccard_score_nDCG[node] = ndcg_score(np.asarray([Jaccard_results[Jaccard_results['source'] == node]['true'].values]), \n",
    "                                              np.asarray([Jaccard_results[Jaccard_results['source'] == node]['Jaccard_pred'].values]))\n",
    "    \n",
    "    if len(PageRank_results[PageRank_results['source'] == node]) > 1:\n",
    "        PageRank_score_nDCG[node] = ndcg_score(np.asarray([PageRank_results[PageRank_results['source'] == node]['true'].values]), \n",
    "                                               np.asarray([PageRank_results[PageRank_results['source'] == node]['PageRank_pred']]))\n",
    "\n",
    "print('The scores for nDCG metrics are:\\n')\n",
    "print('ADA score %.4f' %(sum(ADA_score_nDCG.values())/len(ADA_score_nDCG.values())))\n",
    "print('Jaccard score %.4f' %(sum(Jaccard_score_nDCG.values())/len(Jaccard_score_nDCG.values())))\n",
    "print('PageRank score %.4f' %(sum(PageRank_score_nDCG.values())/len(PageRank_score_nDCG.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TESTING ALGORITHMS USING THE SECOND OPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of edges to select as test-set\n",
    "p = 0.2\n",
    "\n",
    "# graphsize\n",
    "N = len(graph.es)\n",
    "\n",
    "# idxs of all the edges\n",
    "all_idxs = range(N)\n",
    "\n",
    "# sample idxs of edges through the function \"choice\"\n",
    "test_idxs = np.random.choice(a = all_idxs, size = int(p*N), replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51363\n"
     ]
    }
   ],
   "source": [
    "# Remove from the graph the edges on the test set\n",
    "graph_del = Graph.TupleList(tuples, directed = False)\n",
    "graph_del.delete_edges(test_idxs)\n",
    "print(len(graph_del.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set()\n",
    "trainset = set()\n",
    "\n",
    "for idx, one_edge in enumerate(graph.es):\n",
    "\n",
    "    # take n1 and n2 idx from one_edge, that is an igraph edge *object*\n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "\n",
    "    if idx in test_idxs:\n",
    "        ground_truth.add((n1, n2, 1))\n",
    "        \n",
    "    else:\n",
    "        trainset.add((n1, n2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15374"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nodes = set()\n",
    "for n1, n2, _ in ground_truth:\n",
    "    unique_nodes.add(n1)\n",
    "    unique_nodes.add(n2)\n",
    "\n",
    "len(unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 906 ms, total: 2.25 s\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_potential_recommendations = find_nodes_at_distance_2(graph_del, unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019091"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_potential_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in list(all_potential_recommendations)[:len(ground_truth)]:\n",
    "    \n",
    "    # add to ground truth also the potential nodes\n",
    "    n1 = rec[0]\n",
    "    n2 = rec[1]\n",
    "    \n",
    "    ground_truth.add((n1, n2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25680\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we get the adjacency matrix of tweets\n",
    "M = graph_del.get_adjacency_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9b5bc2d199435dbbecc7943ffe2bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# here we run the model ALS\n",
    "model = implicit.als.AlternatingLeastSquares(factors = 10, calculate_training_loss = True,  iterations = 5)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ALS(testset, model):\n",
    "    \"\"\"\n",
    "    predict for a list of observations the score for adding/removing a link\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "\n",
    "    # scroll the obs\n",
    "    for n1, n2, w in testset:\n",
    "        \n",
    "        # take here the low-dimensional vectors returned by the matrix factorization\n",
    "        \n",
    "        array_n1 = model.user_factors[n1,:]\n",
    "        array_n2 = model.item_factors[n2,:]\n",
    "\n",
    "        # multiplying these vectors we generate an approximation for the edge score\n",
    "        one_p = np.dot(array_n1, array_n2)\n",
    "\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "ALS_results = pd.DataFrame(list(ground_truth), columns = [\"n1\", \"n2\", \"true\"])\n",
    "all_predictions = predict_ALS(ALS_results.values, model)\n",
    "\n",
    "# add predictions to df\n",
    "ALS_results[\"pred\"] = all_predictions\n",
    "\n",
    "# convert predictions to binary values: 0 don't add the edge, 1 add it.\n",
    "ALS_results[\"pred\"] = ALS_results[\"pred\"].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAMIC ADAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ADA(u, v, graph):\n",
    "    \"\"\"\n",
    "    compute adamic-adar from scratch\n",
    "    \"\"\"\n",
    "    \n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = graph.neighbors(u)\n",
    "\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = graph.neighbors(v)\n",
    "\n",
    "    # set Z of neighbors of both\n",
    "    bridges = set(outlinks_from_u).intersection(inlinks_to_v)\n",
    "\n",
    "    # degree of nodes in set Z\n",
    "    deg_ = [graph.degree(n) for n in bridges]\n",
    "    \n",
    "    # computing the reciprocal in log-scale\n",
    "    out = [1./np.log2(dd+1) for dd in deg_]\n",
    "\n",
    "    return sum(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JACCARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Jaccard(u,v, graph):\n",
    "    \"\"\"\n",
    "    compute jaccard similarity\n",
    "    \"\"\"\n",
    "\n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = graph.neighbors(u)\n",
    "\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = graph.neighbors(v)\n",
    "\n",
    "    # intesection of the two sets\n",
    "    num = set(outlinks_from_u).intersection(inlinks_to_v)\n",
    "    \n",
    "    # union of the two sets\n",
    "    den = set(outlinks_from_u).union(inlinks_to_v)\n",
    "    \n",
    "    # final division\n",
    "    if len(den) == 0:\n",
    "        out = 0\n",
    "    else:\n",
    "        out = len(num)/len(den)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 3.8 s, total: 1min 29s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Dataframe to store the preductions for each edge\n",
    "ADA_results = pd.DataFrame()\n",
    "Jaccard_results = pd.DataFrame()\n",
    "\n",
    "# Iterate over the pairs of nodes of the ground_truth set\n",
    "for n1, n2, val in ground_truth:\n",
    "    ADA_results = ADA_results.append({'source': n1, 'destination': n2, 'true': val, \n",
    "                                      'pred': compute_ADA(n1, n2, graph_del)}, ignore_index = True)\n",
    "    Jaccard_results = Jaccard_results.append({'source': n1, 'destination': n2, 'true': val, \n",
    "                                              'pred': compute_Jaccard(n1, n2, graph_del)}, ignore_index = True)\n",
    "    \n",
    "# Round the predictions\n",
    "ADA_results['pred'] = ADA_results['pred'].apply(lambda x: round(x))\n",
    "Jaccard_results['pred'] = Jaccard_results['pred'].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>pred</th>\n",
       "      <th>source</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23069.0</td>\n",
       "      <td>0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19233.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7016.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16440.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4863.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3523.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   destination  pred   source  true\n",
       "0      13828.0     0    137.0   1.0\n",
       "1      23069.0     0    607.0   1.0\n",
       "2      19233.0     0   7016.0   0.0\n",
       "3      21201.0     0  16440.0   0.0\n",
       "4       4863.0     0   3523.0   1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADA_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>pred</th>\n",
       "      <th>source</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23069.0</td>\n",
       "      <td>0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19233.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7016.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21201.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16440.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4863.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3523.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   destination  pred   source  true\n",
       "0      13828.0     0    137.0   1.0\n",
       "1      23069.0     0    607.0   1.0\n",
       "2      19233.0     0   7016.0   0.0\n",
       "3      21201.0     1  16440.0   0.0\n",
       "4       4863.0     0   3523.0   1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jaccard_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAGERANK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_dict = {}\n",
    "\n",
    "for n1, _, _ in ground_truth:\n",
    "    if n1 not in PR_dict.keys():\n",
    "        pr = enumerate(graph_del.personalized_pagerank(reset_vertices = node))\n",
    "        PR_dict[n1] = sorted(pr, key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PageRank_results = pd.DataFrame()\n",
    "\n",
    "# PageRank algorithm\n",
    "for n1, n2, val in ground_truth:\n",
    "    predictions = [pagerank for (pagerank, node2) in PR_dict[n1] if node2 == n2]\n",
    "    if len(predictions) != 0:\n",
    "        PageRank_results = PageRank_results.append({'source': node, 'destination': node2, 'true': val, \n",
    "                                                    'pred': predictions}, ignore_index = True)\n",
    "    else:\n",
    "        PageRank_results = PageRank_results.append({'source': node, 'destination': node2, 'true': val, \n",
    "                                                    'pred': 0}, ignore_index = True)\n",
    "    \n",
    "PageRank_results['pred'] = PageRank_results['pred'].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for algorithms is:\n",
      "\n",
      "Adamic-Adar 0.4968\n",
      "Jaccard 0.4173\n",
      "PageRank 0.5000\n",
      "Alternative Least Squares 0.5000\n"
     ]
    }
   ],
   "source": [
    "# ALS\n",
    "correct = ALS_results[ALS_results['pred'] == ALS_results['true']]\n",
    "ALS_accuracy = len(correct)/len(ALS_results)\n",
    "\n",
    "# ADA \n",
    "correct = ADA_results[ADA_results['pred'] == ADA_results['true']]\n",
    "ADA_accuracy = len(correct)/len(ADA_results)\n",
    "\n",
    "# Jaccard\n",
    "correct = Jaccard_results[Jaccard_results['pred'] == Jaccard_results['true']]\n",
    "Jaccard_accuracy = len(correct)/len(Jaccard_results)\n",
    "\n",
    "# PageRank\n",
    "correct = PageRank_results[PageRank_results['pred'] == PageRank_results['true']]\n",
    "PageRank_accuracy = len(correct)/len(PageRank_results)\n",
    "\n",
    "print('The accuracy for algorithms is:\\n')\n",
    "print('Adamic-Adar %.4f' %(ADA_accuracy))\n",
    "print('Jaccard %.4f' %(Jaccard_accuracy))\n",
    "print('PageRank %.4f' %(PageRank_accuracy))\n",
    "print('Alternative Least Squares %.4f' %(ALS_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average precision for algorithms is:\n",
      "\n",
      "Adamic-Adar 0.4999\n",
      "Jaccard 0.4985\n",
      "PageRank 0.5000\n",
      "Alternative Least Squares 0.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "# ALS\n",
    "ALS_avg_precision = average_precision_score(ALS_results['true'], ALS_results['pred'])\n",
    "\n",
    "# ADA \n",
    "ADA_avg_precision = average_precision_score(ADA_results['true'], ADA_results['pred'])\n",
    "\n",
    "# Jaccard\n",
    "Jaccard_avg_precision = average_precision_score(Jaccard_results['true'], Jaccard_results['pred'])\n",
    "\n",
    "# PageRank\n",
    "PageRank_avg_precision = average_precision_score(PageRank_results['true'], PageRank_results['pred'])\n",
    "\n",
    "print('The average precision for algorithms is:\\n')\n",
    "print('Adamic-Adar %.4f' %(ADA_avg_precision))\n",
    "print('Jaccard %.4f' %(Jaccard_avg_precision))\n",
    "print('PageRank %.4f' %(PageRank_avg_precision))\n",
    "print('Alternative Least Squares %.4f' %(ALS_avg_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PREDICT LINKS USING A CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE THE RETWEET GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweet graph \n",
    "df_retweets = df_tweets_100[~df_tweets_100['retweeted_status'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pd.DataFrame(columns = [\"source\", \"destination\"])\n",
    "\n",
    "# add source nodes\n",
    "df_graph[\"source\"] = df_retweets['user'].apply(lambda x: x['screen_name'])\n",
    "\n",
    "# add destination nodes\n",
    "df_graph[\"destination\"] =  df_retweets['retweeted_status'].apply(lambda x: x['user']['screen_name'])\n",
    "\n",
    "# add interaction metrics\n",
    "df_graph[\"retweets\"] = df_retweets['retweeted_status'].apply(lambda x: x['retweet_count'])\n",
    "df_graph[\"favourites\"] = df_retweets['retweeted_status'].apply(lambda x: x['favorite_count'])\n",
    "df_graph[\"quotes\"] = df_retweets['retweeted_status'].apply(lambda x: x['quote_count'])\n",
    "df_graph[\"replies\"] = df_retweets['retweeted_status'].apply(lambda x: x['reply_count'])\n",
    "\n",
    "# edge presence\n",
    "df_graph[\"edge\"] = [1]*len(df_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph.drop_duplicates(subset = [\"source\", \"destination\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favourites</th>\n",
       "      <th>quotes</th>\n",
       "      <th>replies</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>888Paula</td>\n",
       "      <td>SDPNorthEast</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tchevalier10</td>\n",
       "      <td>SenKamalaHarris</td>\n",
       "      <td>2690</td>\n",
       "      <td>35937</td>\n",
       "      <td>221</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPaton4</td>\n",
       "      <td>caljspencer</td>\n",
       "      <td>1090</td>\n",
       "      <td>10770</td>\n",
       "      <td>510</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jkcheney</td>\n",
       "      <td>thatalicewu</td>\n",
       "      <td>3836</td>\n",
       "      <td>11260</td>\n",
       "      <td>1328</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_annalisekc</td>\n",
       "      <td>leensssss</td>\n",
       "      <td>231</td>\n",
       "      <td>1372</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source      destination  retweets  favourites  quotes  replies  edge\n",
       "0      888Paula     SDPNorthEast         1           1       0        0     1\n",
       "1  tchevalier10  SenKamalaHarris      2690       35937     221      502     1\n",
       "2       DPaton4      caljspencer      1090       10770     510       86     1\n",
       "6      jkcheney      thatalicewu      3836       11260    1328      172     1\n",
       "7   _annalisekc        leensssss       231        1372      13        3     1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [tuple(x) for x in df_graph[[\"source\", \"destination\"]].values]\n",
    "graph = Graph.TupleList(tuples, directed = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64203\n"
     ]
    }
   ],
   "source": [
    "print(len(graph.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nodes_at_distance_2(graph):\n",
    "    \"\"\"\n",
    "    starting from a graph this function returns all the nodes at distance 2\n",
    "    \"\"\"\n",
    "    \n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    for n1 in graph.vs:\n",
    "        \n",
    "        # all the nodes at distance 1\n",
    "        nodes_at_most_distant_1 = set(graph.neighborhood(vertices = n1, order = 1))#, mode = 'out'))\n",
    "\n",
    "        # all the nodes at distance 1 and distance 2\n",
    "        nodes_at_most_distant_2 = set(graph.neighborhood(vertices = n1, order = 2))#, mode = 'out'))\n",
    "        \n",
    "        # only the nodes at distance 2\n",
    "        only_nodes_at_distance_2 = nodes_at_most_distant_2 - nodes_at_most_distant_1\n",
    "        \n",
    "        # check if empty set\n",
    "        if len(only_nodes_at_distance_2) > 0:\n",
    "\n",
    "            for n2 in only_nodes_at_distance_2:\n",
    "                \n",
    "                all_potential_recommendations.add((graph.vs[n1.index]['name'], graph.vs[n2]['name']))\n",
    "            \n",
    "    return all_potential_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 7.31 s, total: 1min 17s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_potential_recommendations = find_nodes_at_distance_2(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64203\n"
     ]
    }
   ],
   "source": [
    "all_potential_recommendations = list(all_potential_recommendations)[:len(df_graph)]\n",
    "print(len(all_potential_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame()\n",
    "\n",
    "df_info['users'] = df_retweets['retweeted_status'].apply(lambda x: x['user']['screen_name'])\n",
    "df_info['retweets'] = df_retweets['retweeted_status'].apply(lambda x: x['retweet_count'])\n",
    "df_info['favourites'] = df_retweets['retweeted_status'].apply(lambda x: x['favorite_count'])\n",
    "df_info['quotes'] = df_retweets['retweeted_status'].apply(lambda x: x['quote_count'])\n",
    "df_info['replies'] = df_retweets['retweeted_status'].apply(lambda x: x['reply_count'])\n",
    "\n",
    "df_info.drop_duplicates(\"users\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1_nodes = []\n",
    "n2_nodes = []\n",
    "\n",
    "rets = []\n",
    "favs = []\n",
    "quotes = [] \n",
    "replies = []\n",
    "\n",
    "for rec in all_potential_recommendations:     \n",
    "    n1 = rec[0]\n",
    "    n2 = rec[1]\n",
    "    \n",
    "    n1_nodes.append(n1)\n",
    "    n2_nodes.append(n2)\n",
    "    \n",
    "    if n1 in df_info['users'].values:\n",
    "        rets.append(df_info[df_info['users'] == n1]['retweets'])\n",
    "        favs.append(df_info[df_info['users'] == n1]['favourites'])\n",
    "        quotes.append(df_info[df_info['users'] == n1]['quotes'])\n",
    "        replies.append(df_info[df_info['users'] == n1]['replies'])\n",
    "        \n",
    "    elif n2 in df_info['users'].values:\n",
    "        rets.append(df_info[df_info['users'] == n2]['retweets'])\n",
    "        favs.append(df_info[df_info['users'] == n2]['favourites'])\n",
    "        quotes.append(df_info[df_info['users'] == n2]['quotes'])\n",
    "        replies.append(df_info[df_info['users'] == n2]['replies'])\n",
    "        \n",
    "    else:\n",
    "        rets.append(0)\n",
    "        favs.append(0)\n",
    "        quotes.append(0)\n",
    "        replies.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_potential = pd.DataFrame()\n",
    "df_potential[\"source\"] = n1_nodes\n",
    "df_potential[\"destination\"] = n2_nodes\n",
    "df_potential[\"retweets\"] = rets\n",
    "df_potential[\"favourites\"] = favs\n",
    "df_potential[\"quotes\"] = quotes\n",
    "df_potential[\"replies\"] = replies\n",
    "df_potential[\"edge\"] = [0]*len(df_potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favourites</th>\n",
       "      <th>quotes</th>\n",
       "      <th>replies</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>888Paula</td>\n",
       "      <td>SDPNorthEast</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tchevalier10</td>\n",
       "      <td>SenKamalaHarris</td>\n",
       "      <td>2690</td>\n",
       "      <td>35937</td>\n",
       "      <td>221</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPaton4</td>\n",
       "      <td>caljspencer</td>\n",
       "      <td>1090</td>\n",
       "      <td>10770</td>\n",
       "      <td>510</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jkcheney</td>\n",
       "      <td>thatalicewu</td>\n",
       "      <td>3836</td>\n",
       "      <td>11260</td>\n",
       "      <td>1328</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_annalisekc</td>\n",
       "      <td>leensssss</td>\n",
       "      <td>231</td>\n",
       "      <td>1372</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128401</th>\n",
       "      <td>reginaa_xoo</td>\n",
       "      <td>terrikibiriti</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128402</th>\n",
       "      <td>pefnic</td>\n",
       "      <td>Barbielynn01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128403</th>\n",
       "      <td>pacheco_wilson</td>\n",
       "      <td>Gshu1tz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128404</th>\n",
       "      <td>Time2change17</td>\n",
       "      <td>Heather03807097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128405</th>\n",
       "      <td>outis_xxi</td>\n",
       "      <td>RobertoL91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127977 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source      destination retweets favourites quotes replies  \\\n",
       "0             888Paula     SDPNorthEast        1          1      0       0   \n",
       "1         tchevalier10  SenKamalaHarris     2690      35937    221     502   \n",
       "2              DPaton4      caljspencer     1090      10770    510      86   \n",
       "3             jkcheney      thatalicewu     3836      11260   1328     172   \n",
       "4          _annalisekc        leensssss      231       1372     13       3   \n",
       "...                ...              ...      ...        ...    ...     ...   \n",
       "128401     reginaa_xoo    terrikibiriti        0          0      0       0   \n",
       "128402          pefnic     Barbielynn01        0          0      0       0   \n",
       "128403  pacheco_wilson          Gshu1tz        0          0      0       0   \n",
       "128404   Time2change17  Heather03807097        0          0      0       0   \n",
       "128405       outis_xxi       RobertoL91        0          0      0       0   \n",
       "\n",
       "        edge  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "128401     0  \n",
       "128402     0  \n",
       "128403     0  \n",
       "128404     0  \n",
       "128405     0  \n",
       "\n",
       "[127977 rows x 7 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph = df_graph.append(df_potential, ignore_index = True)\n",
    "\n",
    "# Remove recommendations to oneself\n",
    "df_graph = df_graph[df_graph['source'] != df_graph['destination']]\n",
    "df_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle dataframe\n",
    "from sklearn.utils import shuffle\n",
    "df_graph = shuffle(df_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64203\n",
       "1    63774\n",
       "Name: edge, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph['edge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127977, 4)\n",
      "(127977,)\n"
     ]
    }
   ],
   "source": [
    "## Arrays\n",
    "\n",
    "X = df_graph[[\"retweets\", \"favourites\", \"quotes\", \"replies\"]].values\n",
    "y = df_graph[\"edge\"].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pdp/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "## Support Vector Machine Classifier\n",
    "SVM = svm.LinearSVC()\n",
    "\n",
    "# Train\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier accuracy: 0.9628848257540241\n",
      "SVM average precision score: 0.9597409173041738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('SVM classifier accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "print('SVM average precision score: ' + str(average_precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
